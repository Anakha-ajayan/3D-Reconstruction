{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d802545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of vertices: 34\n",
      "Number of feature pairs: 561\n",
      "Number of rows in the dataframe: 561\n",
      "Feature extraction complete. CSV file saved.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import acos, degrees\n",
    "from itertools import combinations\n",
    "from numpy.linalg import norm\n",
    "from scipy.spatial import cKDTree\n",
    "\n",
    "# --- Function Definitions ---\n",
    "def parse_txt(filepath):\n",
    "    vertices = []\n",
    "    with open(filepath, 'r') as f:\n",
    "        for line in f:\n",
    "            parts = list(map(float, line.strip().split(',')))  # Assuming comma-separated values\n",
    "            vertices.append(parts)\n",
    "    return np.array(vertices)\n",
    "\n",
    "def compute_features(vertices, k_neighbors=3):\n",
    "    tree = cKDTree(vertices)\n",
    "    features = []\n",
    "\n",
    "    for i, j in combinations(range(len(vertices)), 2):\n",
    "        p1, p2 = vertices[i], vertices[j]\n",
    "        vec = p2 - p1\n",
    "        dist = norm(vec)\n",
    "        midpoint = (p1 + p2) / 2\n",
    "        midpoint_height = midpoint[2]\n",
    "        elevation_diff = abs(p1[2] - p2[2])\n",
    "\n",
    "        horizontal = vec.copy(); horizontal[2] = 0\n",
    "        angle_with_horizontal = degrees(acos(\n",
    "            np.clip(np.dot(vec, horizontal) / (norm(vec) * norm(horizontal) + 1e-6), -1, 1)\n",
    "        ))\n",
    "\n",
    "        density_i = len(tree.query_ball_point(p1, r=2.0))\n",
    "        density_j = len(tree.query_ball_point(p2, r=2.0))\n",
    "        local_density = (density_i + density_j) / 2\n",
    "\n",
    "        def get_planarity_score(point):\n",
    "            _, idx = tree.query(point, k=k_neighbors)\n",
    "            neighbor_pts = vertices[idx]\n",
    "            cov = np.cov(neighbor_pts.T)\n",
    "            eigvals = np.linalg.eigvalsh(cov)\n",
    "            return eigvals[0] / (eigvals.sum() + 1e-6)\n",
    "\n",
    "        planarity = (get_planarity_score(p1) + get_planarity_score(p2)) / 2\n",
    "\n",
    "        def get_normal(point):\n",
    "            _, idx = tree.query(point, k=k_neighbors)\n",
    "            neighbor_pts = vertices[idx]\n",
    "            cov = np.cov(neighbor_pts.T)\n",
    "            eigvals, eigvecs = np.linalg.eigh(cov)\n",
    "            return eigvecs[:, np.argmin(eigvals)]\n",
    "\n",
    "        n1 = get_normal(p1)\n",
    "        n2 = get_normal(p2)\n",
    "        normal_diff = degrees(acos(np.clip(np.dot(n1, n2), -1, 1)))\n",
    "\n",
    "        angles = []\n",
    "        for k in range(len(vertices)):\n",
    "            if k != j:\n",
    "                vec2 = vertices[k] - p1\n",
    "                angle = degrees(acos(\n",
    "                    np.clip(np.dot(vec, vec2) / (norm(vec) * norm(vec2) + 1e-6), -1, 1)\n",
    "                ))\n",
    "                angles.append(angle)\n",
    "        angle_to_others = np.mean(angles) if angles else 0\n",
    "\n",
    "        features.append({\n",
    "            'v1': i, 'v2': j,\n",
    "            'distance': dist,\n",
    "            'midpoint_height': midpoint_height,\n",
    "            'angle_with_horizontal': angle_with_horizontal,\n",
    "            'elevation_difference': elevation_diff,\n",
    "            'local_density': local_density,\n",
    "            'planarity_score': planarity,\n",
    "            'normal_difference': normal_diff,\n",
    "            'angle_to_other_edges': angle_to_others\n",
    "        })\n",
    "\n",
    "    return features\n",
    "\n",
    "# === Set Path to TXT File ===\n",
    "txt_file = r\"C:\\Users\\akhil\\OneDrive\\Documents\\3D wireframe reconstruction\\RoofVE-main\\pred_res\\trivandrum\\cluster_144_finCor_Geo.txt\"\n",
    "\n",
    "# --- Feature Extraction ---\n",
    "try:\n",
    "    verts = parse_txt(txt_file)\n",
    "    print(f\"Number of vertices: {len(verts)}\")  # Check number of vertices parsed\n",
    "    feats = compute_features(verts)\n",
    "    print(f\"Number of feature pairs: {len(feats)}\")  # Check number of feature pairs computed\n",
    "    for f in feats:\n",
    "        f[\"file\"] = os.path.basename(txt_file)\n",
    "    all_features = feats\n",
    "except Exception as e:\n",
    "    print(f\"Error processing {txt_file}: {e}\")\n",
    "    all_features = []\n",
    "\n",
    "# --- Check if Features Exist and Save ---\n",
    "df = pd.DataFrame(all_features)\n",
    "print(f\"Number of rows in the dataframe: {len(df)}\")  # Check if dataframe has data\n",
    "if not df.empty:\n",
    "    df.to_csv(\"raw_vertex_pair_features_test.csv\", index=False)\n",
    "    print(\"Feature extraction complete. CSV file saved.\")\n",
    "else:\n",
    "    print(\"No features to save.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e2c0b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Updated dataset saved as 'important_final_test\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Load the dataset\n",
    "df = pd.read_csv(r'raw_vertex_pair_features_test.csv')\n",
    "\n",
    "# Step 2: Define features to drop\n",
    "columns_to_drop = ['midpoint_height', 'planarity_score']\n",
    "\n",
    "# Drop only the columns that actually exist in the DataFrame\n",
    "columns_to_drop = [col for col in columns_to_drop if col in df.columns]\n",
    "df_updated = df.drop(columns=columns_to_drop)\n",
    "\n",
    "# Step 3: Save the updated dataset\n",
    "df_updated.to_csv(\"important_final_test.csv\", index=False)\n",
    "\n",
    "print(\"âœ… Updated dataset saved as 'important_final_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f732777",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akhil\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Predictions and probabilities saved to: C:\\Users\\akhil\\OneDrive\\Documents\\3D wireframe reconstruction\\predictions_with_probabilities.csv\n",
      "ðŸš€ Visualizing predicted edges and vertices with black color...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import joblib\n",
    "\n",
    "# === Step 1: Load the Trained Model ===\n",
    "model_path = r\"C:\\Users\\akhil\\OneDrive\\Documents\\3D wireframe reconstruction\\saved_models_final\\ExtraTrees_best_model.pkl\"\n",
    "model = joblib.load(model_path)\n",
    "\n",
    "# === Step 2: Load Test Data ===\n",
    "test_csv_path = r\"important_final_test.csv\"\n",
    "df_test = pd.read_csv(test_csv_path)\n",
    "\n",
    "# === Step 3: Load the saved Scaler ===\n",
    "scaler_path = r\"C:\\Users\\akhil\\OneDrive\\Documents\\3D wireframe reconstruction\\saved_models_final\\standard_scaler.pkl\"\n",
    "scaler = joblib.load(scaler_path)\n",
    "\n",
    "# === Step 4: Prepare and Scale Test Features ===\n",
    "feature_columns = [\n",
    "    'distance', 'angle_with_horizontal',\n",
    "    'elevation_difference', 'local_density',\n",
    "    'normal_difference', 'angle_to_other_edges'\n",
    "]\n",
    "X_test = df_test[feature_columns].values\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# === Step 5: Predict Probabilities ===\n",
    "y_pred_probs = model.predict_proba(X_test_scaled)\n",
    "df_test['probability'] = y_pred_probs[:, 1]\n",
    "\n",
    "# === Step 6: Dynamic Thresholding Based on Top-K% Confident Edges ===\n",
    "top_k_percent = 0.20 #Keep top 55% confident edges\n",
    "threshold_dynamic = df_test['probability'].quantile(1 - top_k_percent)\n",
    "df_test['prediction'] = (df_test['probability'] >= threshold_dynamic).astype(int)\n",
    "\n",
    "# === Step 7: Extract Predicted Edges ===\n",
    "# Handle NaN values in 'v1' and 'v2'\n",
    "df_test = df_test.dropna(subset=['v1', 'v2'])\n",
    "\n",
    "# Now you can safely convert 'v1' and 'v2' to integers\n",
    "predicted_edges = [\n",
    "    (int(row['v1']), int(row['v2']))\n",
    "    for idx, row in df_test.iterrows() if row['prediction'] == 1\n",
    "]\n",
    "\n",
    "#print(\"âœ… Number of predicted edges after dynamic thresholding:\", len(predicted_edges))\n",
    "\n",
    "# === Step 8: Save Predictions and Probabilities to CSV ===\n",
    "predictions_csv_path = r\"C:\\Users\\akhil\\OneDrive\\Documents\\3D wireframe reconstruction\\predictions_with_probabilities.csv\"\n",
    "df_test[['v1', 'v2', 'prediction', 'probability']].to_csv(predictions_csv_path, index=False)\n",
    "print(f\"âœ… Predictions and probabilities saved to: {predictions_csv_path}\")\n",
    "\n",
    "# === Step 9: Load TXT vertices ===\n",
    "def parse_txt_vertices(filepath):\n",
    "    vertices = []\n",
    "    with open(filepath, 'r') as f:\n",
    "        for line in f:\n",
    "            parts = list(map(float, line.strip().split(',')))  # Assuming comma-separated values\n",
    "            vertices.append(parts)\n",
    "    return np.array(vertices)\n",
    "\n",
    "# Update the file path for your .txt file\n",
    "txt_file_path = r\"C:\\Users\\akhil\\OneDrive\\Documents\\3D wireframe reconstruction\\RoofVE-main\\pred_res\\trivandrum\\cluster_144_finCor_Geo.txt\"\n",
    "verts_np = parse_txt_vertices(txt_file_path)\n",
    "\n",
    "# === Step 10: Visualize with Open3D ===\n",
    "# Create point cloud from vertices\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(verts_np)\n",
    "pcd.paint_uniform_color([0.5, 0.5, 0.5])  # Gray points\n",
    "\n",
    "# Create LineSet with black edges\n",
    "line_set = o3d.geometry.LineSet()\n",
    "line_set.points = o3d.utility.Vector3dVector(verts_np)\n",
    "line_set.lines = o3d.utility.Vector2iVector(predicted_edges)\n",
    "line_set.paint_uniform_color([0, 0, 0])  # Black edges\n",
    "\n",
    "# Visualize\n",
    "print(\"ðŸš€ Visualizing predicted edges and vertices with black color...\")\n",
    "o3d.visualization.draw_geometries([pcd, line_set], window_name=\"Predicted Edges with Black Coloring\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
